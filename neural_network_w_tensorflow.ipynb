{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we split the training, test and validation data into three files, we load them separately and cast them\n",
    "# to the required types\n",
    "extract = np.load('audiobooks_training_data.npz')\n",
    "train_inputs = extract['inputs'].astype(np.float)\n",
    "train_targets = extract['targets'].astype(np.int)\n",
    "\n",
    "# We do the same for our validation and test data\n",
    "extract = np.load('audiobooks_validation_data.npz')\n",
    "validation_inputs = extract['inputs'].astype(np.float)\n",
    "validation_targets = extract['targets'].astype(np.int)\n",
    "\n",
    "extract = np.load('audiobooks_test_data.npz')\n",
    "test_inputs = extract['inputs'].astype(np.float)\n",
    "test_targets = extract['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we define the hyperparameters\n",
    "\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50 # The hidden layer size determines the complexity of the neural network\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "]) # Since we are dealing with a classifier, we use softmax as the activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Adaptive moment estimation as our optimizer. The loss function here is selected in order to pass in \n",
    "# integer inputs and transform into one-hot encoding. In addition, we add the accuracy as part of the metrics to \n",
    "# track during the training of our model\n",
    "\n",
    "# custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/50\n",
      "3579/3579 - 0s - loss: 197.6834 - accuracy: 0.5398 - val_loss: 6.6062 - val_accuracy: 0.6500\n",
      "Epoch 2/50\n",
      "3579/3579 - 0s - loss: 6.2642 - accuracy: 0.7267 - val_loss: 0.2598 - val_accuracy: 0.6900\n",
      "Epoch 3/50\n",
      "3579/3579 - 0s - loss: 1.2197 - accuracy: 0.7664 - val_loss: 0.2104 - val_accuracy: 0.8100\n",
      "Epoch 4/50\n",
      "3579/3579 - 0s - loss: 1.0835 - accuracy: 0.7647 - val_loss: 0.2612 - val_accuracy: 0.6900\n",
      "Epoch 5/50\n",
      "3579/3579 - 0s - loss: 1.0160 - accuracy: 0.7603 - val_loss: 0.1442 - val_accuracy: 0.7000\n",
      "Epoch 6/50\n",
      "3579/3579 - 0s - loss: 0.7411 - accuracy: 0.7631 - val_loss: 0.1043 - val_accuracy: 0.8100\n",
      "Epoch 7/50\n",
      "3579/3579 - 0s - loss: 0.7528 - accuracy: 0.7614 - val_loss: 0.0900 - val_accuracy: 0.8200\n",
      "Epoch 8/50\n",
      "3579/3579 - 0s - loss: 1.0669 - accuracy: 0.7530 - val_loss: 0.1728 - val_accuracy: 0.7600\n",
      "Epoch 9/50\n",
      "3579/3579 - 0s - loss: 0.7039 - accuracy: 0.7773 - val_loss: 0.0939 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c194470>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Training the model above with the above hyperparameters only, we notice that the validation loss increases \n",
    "# often, which is a sign that we are overfitting. Therefore, we need to set an early stopping mechanism\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2) # By default the validation loss is monitored and the iterations\n",
    "# are stopped once the validation loss stops improving\n",
    "\n",
    "model.fit(train_inputs, train_targets, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs,validation_targets), validation_steps= 1,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the validation accuracy attained, we can say that our model learned quite a lot considering that the priors were 50% each. If we are then given customer audiobook information for 10, this implies that we will able to accurately predict the conversion of 8 of those customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 0s 305us/sample - loss: 0.4284 - accuracy: 0.7991\n",
      "Test loss: 0.43 Test accuracy: 79.91%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs,test_targets)\n",
    "\n",
    "print(\"Test loss: {0:.2f} Test accuracy: {1:.2f}%\".format(test_loss,test_accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
